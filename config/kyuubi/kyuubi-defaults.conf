#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

# Basic Kyuubi Configuration
kyuubi.frontend.bind.host=0.0.0.0
kyuubi.frontend.bind.port=10009
kyuubi.authentication=NONE
kyuubi.engine.type=SPARK_SQL
kyuubi.engine.share.level=USER
kyuubi.session.check.interval=5m
kyuubi.session.timeout=1h

# Spark Engine Configuration
kyuubi.engine.spark.main.class=org.apache.kyuubi.engine.spark.SparkSQLEngine
kyuubi.engine.spark.memory=4g
kyuubi.engine.spark.cores=2

# Enable Delta Lake and Iceberg
kyuubi.engine.spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension,org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions
kyuubi.engine.spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog
kyuubi.engine.spark.sql.catalog.spark_catalog.type=hive
kyuubi.engine.spark.sql.catalog.local=org.apache.iceberg.spark.SparkCatalog
kyuubi.engine.spark.sql.catalog.local.type=hadoop
kyuubi.engine.spark.sql.catalog.local.warehouse=file:///opt/warehouse/local

# S3/MinIO Catalog Configuration
kyuubi.engine.spark.sql.catalog.s3=org.apache.iceberg.spark.SparkCatalog
kyuubi.engine.spark.sql.catalog.s3.type=hadoop
kyuubi.engine.spark.sql.catalog.s3.warehouse=s3a://kyuubi-warehouse/
kyuubi.engine.spark.hadoop.fs.s3a.endpoint=http://minio:9000
kyuubi.engine.spark.hadoop.fs.s3a.path.style.access=true
kyuubi.engine.spark.hadoop.fs.s3a.access.key=${AWS_ACCESS_KEY_ID}
kyuubi.engine.spark.hadoop.fs.s3a.secret.key=${AWS_SECRET_ACCESS_KEY}
kyuubi.engine.spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem
kyuubi.engine.spark.hadoop.fs.s3a.connection.maximum=100
kyuubi.engine.spark.hadoop.fs.s3a.fast.upload=true

# Delta Lake S3 Configuration
kyuubi.engine.spark.hadoop.fs.s3a.aws.credentials.provider=org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider

# Hive Metastore Configuration (if using external metastore)
kyuubi.engine.spark.hive.metastore.uris=thrift://hive-metastore:9083
kyuubi.engine.spark.hive.metastore.warehouse.dir=s3a://kyuubi-warehouse/
kyuubi.engine.spark.hive.metastore.schema.verification=false
kyuubi.engine.spark.hive.metastore.schema.verification.record.version=false

# Iceberg Configuration
kyuubi.engine.spark.sql.iceberg.vectorization.enabled=true
kyuubi.engine.spark.sql.iceberg.handle-timestamp-without-timezone=false

# Delta Lake Configuration
kyuubi.engine.spark.delta.logStore.class=org.apache.spark.sql.delta.storage.S3SingleDriverLogStore
kyuubi.engine.spark.delta.retentionDurationCheck.enabled=false

# Spark SQL Configuration
kyuubi.engine.spark.sql.warehouse.dir=s3a://kyuubi-warehouse/
kyuubi.engine.spark.sql.adaptive.enabled=true
kyuubi.engine.spark.sql.adaptive.coalescePartitions.enabled=true
kyuubi.engine.spark.sql.adaptive.advisoryPartitionSizeInBytes=128MB
kyuubi.engine.spark.sql.adaptive.localShuffleReader.enabled=true

# Performance Tuning
kyuubi.engine.spark.sql.execution.arrow.pyspark.enabled=true
kyuubi.engine.spark.sql.execution.arrow.maxRecordsPerBatch=10000
kyuubi.engine.spark.serializer=org.apache.spark.serializer.KryoSerializer
kyuubi.engine.spark.kryoserializer.buffer.max=512m

# Logging Configuration
kyuubi.engine.spark.eventLog.enabled=true
kyuubi.engine.spark.eventLog.dir=file:///opt/spark/events
kyuubi.engine.spark.history.fs.logDirectory=file:///opt/spark/events

# UI Configuration
kyuubi.engine.spark.ui.enabled=true
kyuubi.engine.spark.ui.port=4040
kyuubi.engine.spark.ui.retainedJobs=1000
kyuubi.engine.spark.ui.retainedStages=1000
kyuubi.engine.spark.ui.retainedTasks=100000

# Dynamic Allocation
kyuubi.engine.spark.dynamicAllocation.enabled=true
kyuubi.engine.spark.dynamicAllocation.minExecutors=1
kyuubi.engine.spark.dynamicAllocation.maxExecutors=4
kyuubi.engine.spark.dynamicAllocation.initialExecutors=2

# Shuffle Configuration
kyuubi.engine.spark.sql.shuffle.partitions=200
kyuubi.engine.spark.shuffle.service.enabled=true